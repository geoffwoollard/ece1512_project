{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "cryo_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Rk85R1hLOXI6"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geoffwoollard/ece1512_project/blob/master/nb/cryo_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsUv03M8Ia04",
        "colab_type": "text"
      },
      "source": [
        "# TODO\n",
        "- GPU to TPU? https://www.kdnuggets.com/2019/03/train-keras-model-20x-faster-tpu-free.html\n",
        "- [add gussian noise](https://towardsdatascience.com/noise-its-not-always-annoying-1bd5f0f240f)\n",
        "- window particles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B42q42-cIgc",
        "colab_type": "text"
      },
      "source": [
        "# Goal\n",
        "* implement transfer leaning (using pretrained architecture)\n",
        "\n",
        "# Resources\n",
        "* [Transfer Learning in Keras with Computer Vision Models](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)\n",
        "* [Deep Learning using Transfer Learning -Python Code for ResNet50](https://towardsdatascience.com/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvWgqYkjtmRr",
        "colab_type": "code",
        "outputId": "857bf0da-af8d-49d2-d7e4-5be7ad012c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQBWjn05tt5a",
        "colab_type": "code",
        "outputId": "e05a947b-e713-4d0e-c81d-2a726fa9feb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/mbp/mohammad/ece1512_project\n",
        "import mrc, fit_generator_helper, customizable_deep_network\n",
        "import importlib\n",
        "importlib.reload(fit_generator_helper)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mbp/mohammad/ece1512_project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'fit_generator_helper' from '/content/drive/My Drive/mbp/mohammad/ece1512_project/fit_generator_helper.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPxcUJiFtbJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from keras.utils import np_utils\n",
        "from glob import glob\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9k6oFjbtbJa",
        "colab_type": "text"
      },
      "source": [
        "### Load the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ZOUF17xWaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "files = []\n",
        "#label_d = {'J977':0,'J978':1,'J979':2} # protomer, side, top\n",
        "label_d = {'J1028':0,'J930':1} # +/- micelle. different underlying picks\n",
        "for jdir in label_d.keys():\n",
        "  slow_dir = '/content/drive/My Drive/mbp/mohammad/ece1512_project/data/ouhn_Data1_P1/%s'% jdir\n",
        "  fast_dir = '/%s'% jdir\n",
        "  if not os.path.exists(fast_dir):\n",
        "    shutil.copytree(slow_dir,fast_dir) #!cp -r /content/drive/My\\ Drive/mbp/mohammad/ece1512_project/data/ouhn_Data1_P1/J1028 /\n",
        "  for fname in glob('/%s/downsample/*mrc' % jdir): #glob('/content/drive/My Drive/mbp/mohammad/ece1512_project/data/ouhn_Data1_P1/%s/downsample/*mrc' % jdir): \n",
        "    files.append(fname)\n",
        "    labels.append(label_d[jdir])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPZuXFsHxd88",
        "colab_type": "code",
        "outputId": "5fc1bb1c-3e31-4647-b75e-075d1055ebed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df = fit_generator_helper.parse_files(files,labels)\n",
        "\n",
        "header = mrc.read_header(df['fname'].iloc[0])\n",
        "nx,ny = header['nx'], header['ny']\n",
        "\n",
        "n = int(df['class'].value_counts().min())\n",
        "df0 = df.loc[(df['class'] == 0)].sample(n)\n",
        "df1 = df.loc[(df['class'] == 1)].sample(n)\n",
        "#df2 = df.loc[(df['class'] == 2)].sample(n)\n",
        "\n",
        "df = pd.concat([df0,df1])\n",
        "#df = pd.concat([df0,df1,df2])\n",
        "\n",
        "\n",
        "df = df.sample(df.shape[0])\n",
        "\n",
        "df['class'].value_counts() "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25158\n",
              "0    25158\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggdJWuHrxlc1",
        "colab_type": "code",
        "outputId": "ab46cb53-488e-4c61-89f8-b60f4592a02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test/train split\n",
        "val_n = int(0.02*df.shape[0]) \n",
        "df_val = df.iloc[-val_n:]\n",
        "df = df.iloc[:-val_n]\n",
        "df.shape, df_val.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49310, 3), (1006, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUgi8p4Dxoo0",
        "colab_type": "code",
        "outputId": "f0786cf4-e500-4059-f190-ec0489abb5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "# 12 min 3.4k\n",
        "# 13 min 3.4k\n",
        "# 33s 100 \n",
        "# 2.5s/3.25min 706\n",
        "X_val,Y_val = fit_generator_helper.XY_from_df_batch(df_val,nx=nx,ny=ny,num_classes=df['class'].unique().size)\n",
        "print(X_val.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1006, 64, 64, 1)\n",
            "CPU times: user 131 ms, sys: 42.3 ms, total: 173 ms\n",
            "Wall time: 178 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-20mUvAwwguQ",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSZ3GjiPtbJf",
        "colab_type": "code",
        "outputId": "d241a88b-396d-4fcc-dcc7-9a8c34ad2cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "img_height,img_width = nx,ny \n",
        "num_classes = df['class'].unique().size\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "#base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,1))\n",
        "input_shape=(img_height,img_width,3)\n",
        "restnet = applications.resnet50.ResNet50(weights= 'imagenet', include_top=False, input_shape= input_shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwmTzrWqxxXh",
        "colab_type": "code",
        "outputId": "9a98905b-162e-41fb-a025-dbed76b5597a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output = restnet.layers[-1].output\n",
        "output = Flatten()(output)\n",
        "restnet = Model(restnet.input, output=output)\n",
        "for layer in restnet.layers:\n",
        "    layer.trainable = False\n",
        "restnet.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 16, 16, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 16, 16, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 16, 16, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8192)         0           activation_49[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"fl...)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSSsQ4UR1kiT",
        "colab_type": "code",
        "outputId": "56b838a7-7090-42ef-c8a9-6f9eb582b105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(restnet)\n",
        "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Model)              (None, 8192)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 28,045,697\n",
            "Trainable params: 4,457,985\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk85R1hLOXI6",
        "colab_type": "text"
      },
      "source": [
        "# 1 -> 3 channel\n",
        "* the images are black and white (1 channel). However some architectures have pretrained weights on 3 channel RGB images. We can duplicate each batch in  `fit_generator_helper.XY_from_df_batch`\n",
        "* There are many ways to duplicate data. `np.concatenate` seems comes out the fastest in some [benchmarks](https://stackoverflow.com/questions/39463019/how-to-copy-numpy-array-value-into-higher-dimensions). However in my benchmarks `np.stack` and `np.concatenate` are the fastest, but it depends on the batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdVQQUmQ6Yf",
        "colab_type": "code",
        "outputId": "4cbd70d9-0e31-4ced-f963-6c3dc59db53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_batch = df.iloc[:20]\n",
        "dict_list = df_batch.to_dict('records')\n",
        "x_train = fit_generator_helper.read_particles(dict_list,nx,ny)\n",
        "X = x_train[:,:,:,np.newaxis]\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzoFyDtFSTdl",
        "colab_type": "code",
        "outputId": "3329be86-9044-4717-cf6f-0232b66a2f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.imshow(X[0,:,:,0],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3cfbbccb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BApJXo4ORdLU",
        "colab_type": "code",
        "outputId": "98664787-773f-4627-c3d4-fb35963dc406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X3 = np.stack([x_train]*3, -1)\n",
        "X3.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JVKiWMvSw9m",
        "colab_type": "code",
        "outputId": "55919da3-f1f0-4e7f-988c-e0183ba91d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.imshow(X3[0,:,:,0:3].mean(axis=-1),cmap='gray')\n",
        "np.allclose(X3[0,:,:,0:3].mean(axis=-1),X3[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF1mDUstTlLY",
        "colab_type": "code",
        "outputId": "c218d5a3-fcfe-446c-b45e-d1518a75820e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_batch = df.iloc[:5]\n",
        "dict_list = df_batch.to_dict('records')\n",
        "x_train = fit_generator_helper.read_particles(dict_list,nx,ny)\n",
        "\n",
        "%timeit -n 1000 np.concatenate([x_train[:,:,:,np.newaxis]]*3, axis=-1)\n",
        "%timeit -n 1000 np.repeat(x_train[..., np.newaxis], 3, axis=-1)\n",
        "%timeit -n 1000 np.dstack([x_train]*3) # not right shape. not sure how to reshape\n",
        "%timeit -n 1000 np.stack([x_train]*3, -1)\n",
        "%timeit -n 1000 np.tile(x_train[..., np.newaxis], 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 76.6 µs per loop\n",
            "1000 loops, best of 3: 288 µs per loop\n",
            "1000 loops, best of 3: 72.6 µs per loop\n",
            "1000 loops, best of 3: 87.5 µs per loop\n",
            "1000 loops, best of 3: 291 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnqIHLk5Ugbk",
        "colab_type": "code",
        "outputId": "58a02a2d-cea4-4322-dd92-2e4300122001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_batch = df.iloc[:20]\n",
        "dict_list = df_batch.to_dict('records')\n",
        "x_train = fit_generator_helper.read_particles(dict_list,nx,ny)\n",
        "\n",
        "%timeit -n 1000 np.concatenate([x_train[:,:,:,np.newaxis]]*3, axis=-1)\n",
        "%timeit -n 1000 np.repeat(x_train[..., np.newaxis], 3, axis=-1)\n",
        "%timeit -n 1000 np.dstack([x_train]*3)\n",
        "%timeit -n 1000 np.stack([x_train]*3, -1)\n",
        "%timeit -n 1000 np.tile(x_train[..., np.newaxis], 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 345 µs per loop\n",
            "1000 loops, best of 3: 1.03 ms per loop\n",
            "1000 loops, best of 3: 236 µs per loop\n",
            "1000 loops, best of 3: 333 µs per loop\n",
            "1000 loops, best of 3: 983 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN7psdSTwcf",
        "colab_type": "code",
        "outputId": "dcb3c0df-1bdd-4874-9609-d393b687a6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_batch = df.iloc[:50]\n",
        "dict_list = df_batch.to_dict('records')\n",
        "x_train = fit_generator_helper.read_particles(dict_list,nx,ny)\n",
        "\n",
        "%timeit -n 1000 np.concatenate([x_train[:,:,:,np.newaxis]]*3, axis=-1)\n",
        "%timeit -n 1000 np.repeat(x_train[..., np.newaxis], 3, axis=-1)\n",
        "%timeit -n 1000 np.dstack([x_train]*3)\n",
        "%timeit -n 1000 np.stack([x_train]*3, -1)\n",
        "%timeit -n 1000 np.tile(x_train[..., np.newaxis], 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 964 µs per loop\n",
            "1000 loops, best of 3: 2.5 ms per loop\n",
            "1000 loops, best of 3: 499 µs per loop\n",
            "1000 loops, best of 3: 742 µs per loop\n",
            "1000 loops, best of 3: 2.38 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZLfcKYLYi7C",
        "colab_type": "code",
        "outputId": "8cb62b0c-387f-42d7-da79-1c0ed95e6bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/mbp/mohammad/ece1512_project\n",
        "import mrc, fit_generator_helper, customizable_deep_network\n",
        "import importlib\n",
        "importlib.reload(fit_generator_helper)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mbp/mohammad/ece1512_project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'fit_generator_helper' from '/content/drive/My Drive/mbp/mohammad/ece1512_project/fit_generator_helper.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4PG5cJzXS--",
        "colab_type": "code",
        "outputId": "2d8ef8c4-e128-43c7-9e90-e3da58ddd2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_batch, Y_batch = fit_generator_helper.XY_from_df_batch(df.iloc[:5],\n",
        "                                      nx,\n",
        "                                      ny,\n",
        "                                      do_1to3channel=True\n",
        "    \n",
        ")\n",
        "X_batch.shape, Y_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 64, 64, 3), (5,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX_MvbymO4qC",
        "colab_type": "code",
        "outputId": "644c5177-a12e-426b-ed63-60f01d9291aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit_generator_helper.image_loader(df.sample(4),\n",
        "                                  do_augment=True,\n",
        "                                  batch_size=batch_size,\n",
        "                                  nx=nx,ny=ny,\n",
        "                                  num_classes=df['class'].unique().size,\n",
        "                                  do_1to3channel=True\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object image_loader at 0x7f3cfc286780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg4yN6zta1rU",
        "colab_type": "text"
      },
      "source": [
        "We also need to reshape the Y data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGejGn7a09V",
        "colab_type": "code",
        "outputId": "a1605221-0d77-46f2-e529-f6e31f551360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = 2\n",
        "Y = fit_generator_helper.to_categorical(df_batch['class'].values, num_classes=num_classes,dtype='int')\n",
        "df_batch['class'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpCU50tFOZwY",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qff9WDZmyI3N",
        "colab_type": "code",
        "outputId": "9b7122e2-18d9-45bf-e0b5-923673ef3156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 20 # do not put this too large. 100 too big. 50 getting big, perhaps can go bigger. 20 ok\n",
        "n=df.shape[0]\n",
        "steps_per_epoch = np.floor(df.sample(n).shape[0] / batch_size) # 110 for 11k particles\n",
        "steps_per_epoch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2465.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lfmVQB7PKtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "dateTimeObj = datetime.now()\n",
        "!mkdir /keras_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4RB2OwAdBTE",
        "colab_type": "code",
        "outputId": "2ffd76a5-cbbd-480c-f269-8afdbd052f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def XY_to_3channel(X,Y):\n",
        "  X3 = np.stack([X[:,:,:,0]]*3, -1)\n",
        "  Y3 = np.argmax(Y,axis=1)\n",
        "  return(X3,Y3)\n",
        "XY_aug_list = [fit_generator_helper.batch_image_augment(X_val,Y_val,batch_size=X_val.shape[0],rotation_range=180) for x in range(1)]\n",
        "X, Y = XY_aug_list[0]\n",
        "X3, Y3 = XY_to_3channel(X,Y)\n",
        "model.evaluate(X3, Y3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1006/1006 [==============================] - 1s 705us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7480953226743589, 0.5089462995529175]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f0Gx-HZcJCF",
        "colab_type": "code",
        "outputId": "af3d4ebd-7991-4000-ad35-3b78c88fc172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_fname = '/keras_models/micelle_aug_rn50_pretrainedin'\n",
        "do_1to3channel=True\n",
        "for epoch in range(40):\n",
        "    print('actual epoch %i' % epoch)\n",
        "    model.fit_generator(fit_generator_helper.image_loader(df.sample(n),\n",
        "                                                          do_augment=True,\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          nx=nx,ny=ny,\n",
        "                                                          num_classes=df['class'].unique().size,\n",
        "                                                          do_1to3channel=do_1to3channel,\n",
        "                                                          ),\n",
        "                        steps_per_epoch=steps_per_epoch, # steps_per_epoch is number of batches per epoch\n",
        "                        epochs=1,\n",
        "                        )\n",
        "    \n",
        "    XY_aug_list = [fit_generator_helper.batch_image_augment(X_val,Y_val,batch_size=X_val.shape[0],rotation_range=180) for x in range(1)]\n",
        "    for X, Y in XY_aug_list:\n",
        "      X, Y = XY_to_3channel(X,Y)\n",
        "      scores = model.evaluate(X, Y)\n",
        "      print ('epoch %s' % epoch, \"Loss = \" + str(scores[0]), \"Test Accuracy = \" + str(scores[1]))\n",
        "      #model.save(model_fname+dateTimeObj.strftime(\"%Y%m%d-%H%M%S\")+'_ep%i.h5'%epoch)\n",
        "      Y_pred = model.predict(X)\n",
        "      print(confusion_matrix(Y, Y_pred > 0.5))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual epoch 0\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.7220 - accuracy: 0.5298\n",
            "1006/1006 [==============================] - 1s 685us/step\n",
            "epoch 0 Loss = 0.7078211091858729 Test Accuracy = 0.49701789021492004\n",
            "[[ 95 409]\n",
            " [ 97 405]]\n",
            "actual epoch 1\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6941 - accuracy: 0.5409\n",
            "1006/1006 [==============================] - 1s 681us/step\n",
            "epoch 1 Loss = 0.7059611668643611 Test Accuracy = 0.48906561732292175\n",
            "[[311 193]\n",
            " [321 181]]\n",
            "actual epoch 2\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6868 - accuracy: 0.5587\n",
            "1006/1006 [==============================] - 1s 684us/step\n",
            "epoch 2 Loss = 0.7218612874478516 Test Accuracy = 0.5218687653541565\n",
            "[[ 65 439]\n",
            " [ 42 460]]\n",
            "actual epoch 3\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6828 - accuracy: 0.5666\n",
            "1006/1006 [==============================] - 1s 678us/step\n",
            "epoch 3 Loss = 0.7059369870493 Test Accuracy = 0.5357853174209595\n",
            "[[104 400]\n",
            " [ 67 435]]\n",
            "actual epoch 4\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6806 - accuracy: 0.5681\n",
            "1006/1006 [==============================] - 1s 709us/step\n",
            "epoch 4 Loss = 0.7559979073332982 Test Accuracy = 0.4990059733390808\n",
            "[[ 15 489]\n",
            " [ 15 487]]\n",
            "actual epoch 5\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6779 - accuracy: 0.5753\n",
            "1006/1006 [==============================] - 1s 678us/step\n",
            "epoch 5 Loss = 0.7547148416340944 Test Accuracy = 0.5029820799827576\n",
            "[[  5 499]\n",
            " [  1 501]]\n",
            "actual epoch 6\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6754 - accuracy: 0.5808\n",
            "1006/1006 [==============================] - 1s 694us/step\n",
            "epoch 6 Loss = 0.7473625763510141 Test Accuracy = 0.5009940266609192\n",
            "[[  8 496]\n",
            " [  6 496]]\n",
            "actual epoch 7\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6752 - accuracy: 0.5776\n",
            "1006/1006 [==============================] - 1s 683us/step\n",
            "epoch 7 Loss = 0.7379801904941885 Test Accuracy = 0.5059642195701599\n",
            "[[ 14 490]\n",
            " [  7 495]]\n",
            "actual epoch 8\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.6727 - accuracy: 0.5819\n",
            "1006/1006 [==============================] - 1s 698us/step\n",
            "epoch 8 Loss = 0.7144792361951491 Test Accuracy = 0.5268389582633972\n",
            "[[ 73 431]\n",
            " [ 45 457]]\n",
            "actual epoch 9\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.6740 - accuracy: 0.5833\n",
            "1006/1006 [==============================] - 1s 685us/step\n",
            "epoch 9 Loss = 0.7305145319366075 Test Accuracy = 0.512922465801239\n",
            "[[ 24 480]\n",
            " [ 10 492]]\n",
            "actual epoch 10\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6724 - accuracy: 0.5829\n",
            "1006/1006 [==============================] - 1s 676us/step\n",
            "epoch 10 Loss = 0.7740068831453266 Test Accuracy = 0.5\n",
            "[[  1 503]\n",
            " [  0 502]]\n",
            "actual epoch 11\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 31ms/step - loss: 0.6710 - accuracy: 0.5874\n",
            "1006/1006 [==============================] - 1s 681us/step\n",
            "epoch 11 Loss = 0.713520017580294 Test Accuracy = 0.5308151245117188\n",
            "[[ 71 433]\n",
            " [ 39 463]]\n",
            "actual epoch 12\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 31ms/step - loss: 0.6690 - accuracy: 0.5914\n",
            "1006/1006 [==============================] - 1s 685us/step\n",
            "epoch 12 Loss = 0.7637415219016862 Test Accuracy = 0.5119284391403198\n",
            "[[ 40 464]\n",
            " [ 27 475]]\n",
            "actual epoch 13\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6678 - accuracy: 0.5929\n",
            "1006/1006 [==============================] - 1s 684us/step\n",
            "epoch 13 Loss = 0.8090370738245621 Test Accuracy = 0.4940357804298401\n",
            "[[  0 504]\n",
            " [  5 497]]\n",
            "actual epoch 14\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6672 - accuracy: 0.5932\n",
            "1006/1006 [==============================] - 1s 687us/step\n",
            "epoch 14 Loss = 0.7347933384580593 Test Accuracy = 0.5099403858184814\n",
            "[[ 34 470]\n",
            " [ 23 479]]\n",
            "actual epoch 15\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6658 - accuracy: 0.5976\n",
            "1006/1006 [==============================] - 1s 682us/step\n",
            "epoch 15 Loss = 0.7175409806888573 Test Accuracy = 0.5049701929092407\n",
            "[[ 18 486]\n",
            " [ 12 490]]\n",
            "actual epoch 16\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6676 - accuracy: 0.5940\n",
            "1006/1006 [==============================] - 1s 689us/step\n",
            "epoch 16 Loss = 0.8143940500426246 Test Accuracy = 0.5029820799827576\n",
            "[[  6 498]\n",
            " [  2 500]]\n",
            "actual epoch 17\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 76s 31ms/step - loss: 0.6646 - accuracy: 0.5997\n",
            "1006/1006 [==============================] - 1s 695us/step\n",
            "epoch 17 Loss = 0.7530063342147508 Test Accuracy = 0.5139164924621582\n",
            "[[ 33 471]\n",
            " [ 18 484]]\n",
            "actual epoch 18\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6665 - accuracy: 0.5931\n",
            "1006/1006 [==============================] - 1s 681us/step\n",
            "epoch 18 Loss = 0.7326223628658424 Test Accuracy = 0.5099403858184814\n",
            "[[ 22 482]\n",
            " [ 11 491]]\n",
            "actual epoch 19\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 76s 31ms/step - loss: 0.6662 - accuracy: 0.5953\n",
            "1006/1006 [==============================] - 1s 669us/step\n",
            "epoch 19 Loss = 0.7348688804131616 Test Accuracy = 0.5139164924621582\n",
            "[[ 50 454]\n",
            " [ 35 467]]\n",
            "actual epoch 20\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 76s 31ms/step - loss: 0.6662 - accuracy: 0.5917\n",
            "1006/1006 [==============================] - 1s 675us/step\n",
            "epoch 20 Loss = 0.7617624162679638 Test Accuracy = 0.5079522728919983\n",
            "[[ 20 484]\n",
            " [ 11 491]]\n",
            "actual epoch 21\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 76s 31ms/step - loss: 0.6644 - accuracy: 0.5982\n",
            "1006/1006 [==============================] - 1s 683us/step\n",
            "epoch 21 Loss = 0.771073757298661 Test Accuracy = 0.5009940266609192\n",
            "[[ 19 485]\n",
            " [ 17 485]]\n",
            "actual epoch 22\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6655 - accuracy: 0.5954\n",
            "1006/1006 [==============================] - 1s 688us/step\n",
            "epoch 22 Loss = 0.7523797163906438 Test Accuracy = 0.5079522728919983\n",
            "[[ 16 488]\n",
            " [  7 495]]\n",
            "actual epoch 23\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6650 - accuracy: 0.5975\n",
            "1006/1006 [==============================] - 1s 684us/step\n",
            "epoch 23 Loss = 0.7447787067051199 Test Accuracy = 0.5059642195701599\n",
            "[[  9 495]\n",
            " [  2 500]]\n",
            "actual epoch 24\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6659 - accuracy: 0.5982\n",
            "1006/1006 [==============================] - 1s 673us/step\n",
            "epoch 24 Loss = 0.7620142038252434 Test Accuracy = 0.5019880533218384\n",
            "[[  3 501]\n",
            " [  0 502]]\n",
            "actual epoch 25\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6634 - accuracy: 0.5995\n",
            "1006/1006 [==============================] - 1s 676us/step\n",
            "epoch 25 Loss = 0.7659430449335997 Test Accuracy = 0.5019880533218384\n",
            "[[ 10 494]\n",
            " [  7 495]]\n",
            "actual epoch 26\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 80s 32ms/step - loss: 0.6635 - accuracy: 0.5991\n",
            "1006/1006 [==============================] - 1s 694us/step\n",
            "epoch 26 Loss = 0.795682692741068 Test Accuracy = 0.4990059733390808\n",
            "[[  3 501]\n",
            " [  3 499]]\n",
            "actual epoch 27\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6646 - accuracy: 0.5956\n",
            "1006/1006 [==============================] - 1s 682us/step\n",
            "epoch 27 Loss = 0.8720519009451743 Test Accuracy = 0.4990059733390808\n",
            "[[  0 504]\n",
            " [  0 502]]\n",
            "actual epoch 28\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6636 - accuracy: 0.5998\n",
            "1006/1006 [==============================] - 1s 685us/step\n",
            "epoch 28 Loss = 0.7382181296291692 Test Accuracy = 0.5109344124794006\n",
            "[[ 15 489]\n",
            " [  3 499]]\n",
            "actual epoch 29\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6637 - accuracy: 0.5974\n",
            "1006/1006 [==============================] - 1s 690us/step\n",
            "epoch 29 Loss = 0.7504198026230511 Test Accuracy = 0.5029820799827576\n",
            "[[ 11 493]\n",
            " [  7 495]]\n",
            "actual epoch 30\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6618 - accuracy: 0.6005\n",
            "1006/1006 [==============================] - 1s 693us/step\n",
            "epoch 30 Loss = 0.7888858550585525 Test Accuracy = 0.5188866853713989\n",
            "[[ 26 478]\n",
            " [  6 496]]\n",
            "actual epoch 31\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6618 - accuracy: 0.6007\n",
            "1006/1006 [==============================] - 1s 676us/step\n",
            "epoch 31 Loss = 0.7726806103590705 Test Accuracy = 0.5089462995529175\n",
            "[[ 20 484]\n",
            " [ 10 492]]\n",
            "actual epoch 32\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6634 - accuracy: 0.5986\n",
            "1006/1006 [==============================] - 1s 684us/step\n",
            "epoch 32 Loss = 0.8424813800730241 Test Accuracy = 0.4990059733390808\n",
            "[[  0 504]\n",
            " [  0 502]]\n",
            "actual epoch 33\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6611 - accuracy: 0.6036\n",
            "1006/1006 [==============================] - 1s 682us/step\n",
            "epoch 33 Loss = 0.7240401667581637 Test Accuracy = 0.5089462995529175\n",
            "[[ 35 469]\n",
            " [ 25 477]]\n",
            "actual epoch 34\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.6643 - accuracy: 0.5991\n",
            "1006/1006 [==============================] - 1s 702us/step\n",
            "epoch 34 Loss = 0.7987278396519231 Test Accuracy = 0.4990059733390808\n",
            "[[  0 504]\n",
            " [  0 502]]\n",
            "actual epoch 35\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.6608 - accuracy: 0.6038\n",
            "1006/1006 [==============================] - 1s 689us/step\n",
            "epoch 35 Loss = 0.824206160622136 Test Accuracy = 0.4990059733390808\n",
            "[[  0 504]\n",
            " [  0 502]]\n",
            "actual epoch 36\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6620 - accuracy: 0.6004\n",
            "1006/1006 [==============================] - 1s 697us/step\n",
            "epoch 36 Loss = 0.7831695756428758 Test Accuracy = 0.5009940266609192\n",
            "[[  2 502]\n",
            " [  0 502]]\n",
            "actual epoch 37\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 79s 32ms/step - loss: 0.6627 - accuracy: 0.6012\n",
            "1006/1006 [==============================] - 1s 687us/step\n",
            "epoch 37 Loss = 0.7879358695942176 Test Accuracy = 0.5009940266609192\n",
            "[[  3 501]\n",
            " [  1 501]]\n",
            "actual epoch 38\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6613 - accuracy: 0.6046\n",
            "1006/1006 [==============================] - 1s 688us/step\n",
            "epoch 38 Loss = 0.840382312093056 Test Accuracy = 0.4990059733390808\n",
            "[[  0 504]\n",
            " [  0 502]]\n",
            "actual epoch 39\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 78s 32ms/step - loss: 0.6611 - accuracy: 0.6030\n",
            "1006/1006 [==============================] - 1s 679us/step\n",
            "epoch 39 Loss = 0.8360049649924929 Test Accuracy = 0.5\n",
            "[[  2 502]\n",
            " [  1 501]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RZb2CQ9QPQY",
        "colab_type": "code",
        "outputId": "a324fed0-cf9d-4e5e-b0a3-810cfc49668d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model_fname = '/keras_models/micelle_aug_rn50_pretrainedin'\n",
        "do_1to3channel=True\n",
        "for epoch in range(40,41):\n",
        "    print('actual epoch %i' % epoch)\n",
        "    model.fit_generator(fit_generator_helper.image_loader(df.sample(n),\n",
        "                                                          do_augment=True,\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          nx=nx,ny=ny,\n",
        "                                                          num_classes=df['class'].unique().size,\n",
        "                                                          do_1to3channel=do_1to3channel,\n",
        "                                                          ),\n",
        "                        steps_per_epoch=steps_per_epoch, # steps_per_epoch is number of batches per epoch\n",
        "                        epochs=1,\n",
        "                        )\n",
        "    \n",
        "    XY_aug_list = [fit_generator_helper.batch_image_augment(X_val,Y_val,batch_size=X_val.shape[0],rotation_range=180) for x in range(1)]\n",
        "    for X, Y in XY_aug_list:\n",
        "      X, Y = XY_to_3channel(X,Y)\n",
        "      scores = model.evaluate(X, Y)\n",
        "      print ('epoch %s' % epoch, \"Loss = \" + str(scores[0]), \"Test Accuracy = \" + str(scores[1]))\n",
        "      #model.save(model_fname+dateTimeObj.strftime(\"%Y%m%d-%H%M%S\")+'_ep%i.h5'%epoch)\n",
        "      Y_pred = model.predict(X)\n",
        "      print(confusion_matrix(Y, Y_pred > 0.5))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual epoch 40\n",
            "Epoch 1/1\n",
            "2465/2465 [==============================] - 77s 31ms/step - loss: 0.6631 - accuracy: 0.5965\n",
            "1006/1006 [==============================] - 1s 674us/step\n",
            "epoch 40 Loss = 0.790411197286003 Test Accuracy = 0.5009940266609192\n",
            "[[  2 502]\n",
            " [  0 502]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdyafyP-2IO1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "|jobs | pix | train acc (%) | val acc (%) | epochs|notes|\n",
        "|-|-|-|-|-|-|\n",
        "|J1028,J930. 25k each. +/- micelle. different underlying picks. `micelle_aug_rn50_pretrainedin`|64| 58.2 ep 20, 59.4 ep 30, 60.0 ep 40 | 50 for all epochs up to 40, pretty much all being predicted as same class  |40|aug. resnet 50 imagenet weights. copied 1 to 3 channels|\n"
      ]
    }
  ]
}